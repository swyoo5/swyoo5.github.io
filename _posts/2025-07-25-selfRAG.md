---
layout: single
title:  "[LLM] Self-RAG : Learning To Retrieve, Generate, and Critique Through Self-Reflection"
categories: [Programming, LLM, RAG, Project]
tag: [Programming, LLM, RAG, Project]
toc: true
author_profile: false
sidebar:
    nav: "docs"
---

[Self-RAG](https://arxiv.org/abs/2310.11511)

# 개요

- 해당 논문은 LLM의 정확성과 정보 검색 능력을 향상시키는 프레임워크 Self-RAG를 소개
- Self-RAG는 기존의 RAG를 확장하여 모델이 언제 외부 정보를 검색하고, 검색된 정보의 관련성을 평가하고, 자신이 생성한 답변을 비판적으로 검토할 수 있도록 훈련

# 기존 문제점

- 환각 : 불완전한 정보를 그럴듯하게 지어냄
- 경직성 : 질문의 특성, 복잡성에 관계없이 항상 고정된 수의 문서를 검색
  - 단순한 질문에도 불필요한 검색으로 효율성 저하
  - 관련성이 낮은 문서 포함 → 품질 저하
- 모델이 검색된 답변을 하도록 훈련되지 않아 생성 결과, 검색 문서 불일치

# 해결방안 : Self-RAG

- 반성 토큰
  - Retrieve 토큰 : 외부 정보 검색이 필요한지 여부 결정
  - ISREL 토큰 : 검색된 문서가 현재 질문 & 생성 작업과 얼마나 관련 있는지 평가
  - ISSUP 토큰 : 생성된 답변이 문서에 의해 얼마나 잘 뒷받침되는지 평가
  - ISUSE 토큰 : 생성된 답변이 얼마나 유용한지 평가

# 훈련 프로세스

- 비판 모델 훈련
  - 강력한 LLM을 프롬프팅하여 다양한 입력-출력 쌍에 대한 반성 토큰 값 생성
  - 이 데이터로 비판 모델을 훈련하여 주어진 입력, 출력, 검색 문서에 대한 반성 토큰을 예측하게 훈련
- 생성 모델 훈련
  - 비판 모델의 예측을 통합하여 기존 데이터셋 증강
  - 증강된 데이터로 생성 모델을 훈련하여 입력에 따른 적절한 텍스트와 반성 토큰을 생성하도록 함

# 추론 프로세스

1. 검색 결정 : 모델이 현재 상태에서 Retrieve 토큰 예측 → 외부 정보 검색 여부 결정
2. 검색 및 평가 : 검색이 필요한 경우, 관련 문서를 가져옴. 모델은 ISREL 토큰을 생성하여 관련성을 평가
3. 다중 경로 생성 : 모델이 검색된 여러 문서를 바탕으로 ISSUP 토큰을 생성하여 사실성 평가
4. 유용성 평가 : 생성된 텍스트의 유용성 평가

# Self-RAG 입출력

1. 비판 모델 훈련

- 입력데이터
  - 사용자 질문
  - LLM 응답
  - 검색된 문서 
- 츨력데이터
  - 반성 토큰
    - Retrieve : Yes/No(검색 필요 여부)
    - ISREL : “Relevant”, “Partially”, “Irrelevant”(문서 관련성)
    - ISSUP  “Supported”, “Partially”, “No Support”(문서의 응답 뒷받침 정도)
    - ISUSE : “1”, “2”, “3”, “4”, “5”(응답 유용성)

1. 생성 모델 훈련

- 입력데이터
  - 사용자 질문
  - 검색된 문서
- 출력데이터
  - 증강된 응답
    - 반성 토큰(Retrieve, ISREL, ISSUP, ISUSE)
    - 검색된 문서 내용
    - LLM 응답

1. 추론

- 입력데이터
  - 사용자 질문
- 중간 처리 데이터
  - 반성 토큰(Retrieve, ISREL, ISSUP, ISUSE)
  - 검색된 여러 문서
- 출력데이터
  - 정제된 LLM 응답 : 반성 토큰과 문서를 제외하고 실제 텍스트 응답만 포함

 