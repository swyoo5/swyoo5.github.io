---
layout: single
title:  "[LLM] Kimi-K2"
categories: [Programming, LLM, RAG, Project]
tag: [Programming, LLM, RAG, Project]
toc: true
author_profile: false
sidebar:
    nav: "docs"
---

# 기본 사양

- 핵심 파라미터 : 1000B 파라미터 보유, 각 토큰을 처리할 때 32B 파라미터를 선택적으로 활성화.
- 컨텍스트 : 128,000 토큰
- MoE : 384개의 Routed Expert + 1개의 Shared Expert(토큰 처리 과정)
- 모델 버전 : Kimi-K2-Base, Kimi-K2-Instruct
- MuonClip 옵티마이저 : 15.5조개의 토큰으로 훈련하는 과정에서 발생하는 불안정성 제어

# MoE

- 61개의 레이어 중 60개를 MoE레이어로 구성
- 라우터 네트워크가 384개의 전문가 중 가장 관련이 높다고 판단하는 상위 8개의 전문가 선택
- 공유 전문가 : 모든 토큰 처리에 항상 활성화. 언어의 보편적 규칙, 기본적인 추론 패턴 등 공통적이고 기초적인 지식 학습 → 도메인 전문가는 도메인 특화 지식을 익히는데 자원을 집중할 수 있음

# 옵티마이저

- qk-clip : 각 옵티마이저 업데이트 단계 이후에 Attention의 Query, Key 가중치를 직접 재조정함. Attention Score가 비정상적으로 커지는 것을 방지