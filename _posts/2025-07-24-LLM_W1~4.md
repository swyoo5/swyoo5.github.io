---
layout: single
title:  "[LLM] 자동차 메뉴얼 질의응답 RAG W1-4"
categories: [Programming, LLM, RAG, Project]
tag: [Programming, LLM, RAG, Project]
toc: true
author_profile: false
sidebar:
    nav: "docs"

---

# W1(2025/03/10~2025/03/14)

# 목적

- 자동차 메뉴얼처럼 분량이 많고 세부 정보가 다양한 문서를 대상으로, 사용자가 자연어로 질문했을 때 필요한 정보를 정확하고 빠르게 찾아 대화형으로 제공하기 위해 RAG 방식을 적용. 
- 벡터 검색으로 문서에서 관련 텍스트 또는 이미지를 추출하고, 생성 모델을 통해 효율적으로 대용량 문서를 기반으로 정확한 정보를 반환하는 것이 목표.



# PDF 문서 텍스트 및 이미지 추출

PDF 문서에서 텍스트와 이미지를 추출하기 위해 PyMuPDF(fitz) 라이브러리를 활용

![image-20250726144420956](/images/2025-07-24-LLM_W1~4/image-20250726144420956.png)

# 텍스트 임베딩 생성

1. bge-m3

- 다국어 문서 검색 및 자연어 이해에 최적화된 모델
- 검색, 추천 시스템, 문서 요약, 문서 분류 등의 태스크에 활용됨
- 상대적으로 한국어 검색에 최적화되어 있지 않음.

1. KoSimCSE

- SimCSE 모델을 한국어 문장으로 파인튜닝시킨 모델
- contrastive learning 기반의 임베딩 모델
- 한국어 문서 기반 RAG에서 의미적으로 더 유사한 문장 검색 가능

1. intfloat-multilingual-e5-large

- E5(Embedding-Enhanced, Efficient, and Effective) 아키텍처 기반 다국어 모델로, 문서 검색 최적화
- E5 : 검색, 의미적 유사도 측정을 최적화하기 위해 설계된 아키텍처
  - Embedding-Enhanced => query : {}, passage : {}와 같은 프롬프트 구조를 도입하여 검색에 최적화
  - Efficient : contrastive learning을 활용해 훈련하여 더 나은 검색 성능
  - Effective : 다양한 태스크에서 Bert기반 모델보다 더 높은 성능 발발휘
- 여러 언어의 문서를 지원하므로, 한국어와 영어가 혼합된 데이터에서도 강점
- 한국어 데이터가 상대적으로 적음

1. jhgan-kosbert-multitask

- 한국어에 최적화된 KoBERT 기반 문장 임베딩 모델
- 다양한 한국어 NLP 태스크에 활용

1. sentence-transformers-xml-r-100langs-bert-base

- 다국어 문서 검색과 자연어 처리에 강한 문장 임베딩 모델
- 100개의 언어를 지원하며, 다국어 문서 검색이 필요한 RAG에서 유리
- 한국어 최적화 부족

1. text-embedding-3-small

- OpenAI에서 개발한 경량화된 최신 문장 임베딩 모델
- 효율적이고 정확한 임베딩 생성
- 다국어 지원

# ChromaDB 기반 벡터 검색 시스템 구축

1. 텍스트 벡터 저장 및 검색

- PersistentClient를 사용하여 벡터를 영구 저장
- query() 함수를 사용하여 질문과 가장 유사한 문서 상위 10개를 검색

# 생성모델

1. KoAlpaca

- Llama 모델을 한국어로 파인튜닝한 모델
- 주로 한국어 QA, 요약에 활용됨
- 기존 Llama보다 한국어 표현력이 개선되어, 한국어 기반 RAG에서 적절한 응답을 생성할 가능성이 높음음

1. Qwen-72b

- Alibaba에서 개발한 72B 규모의 모델
- 다국어 지원(한국어, 영어 혼합 문서에 대해서 높은 성능) 및 최신 GPT-4 계열과 경쟁하는 수준의 성능

1. Llama3-70b-Instruct

- Llama3 기반 70B 모델
- Instruction Tuning이 되어 있어 RAG 시스템에서 문서 기반 QA 성능이 뛰어남
- 논리적 응답, 창의적인 텍스트 생성, 코드 생성 등에 강점

1. GPT-4o-mini

- OpenAI에서 개발한 GPT-4 계열의 경량화된 모델
- GPT-3.5보다 성능이 뛰어나고 속도가 빠름

# 문제 발생

- KoAlpaca-12.8b, qwen2-72b 등 검색된 문서 내용을 포함한 프롬프트를 입력했음에도 검색 정보를 제대로 활용하지 못함
- 사전 학습된 정보를 기반으로 검색 결과와 무관한 답변 생성
- 문맥이 자연스럽지 못한 문제 발생
- 하이퍼 파라미터, 프롬프트 수정을 통해 개선을 시도하였으나 개선의 여지가 보이지 않음 => OpenAI의 임베딩, 생성모델 활용



# LLM기반 질의응답 시스템 구축

- OpenAI의 gpt-4o-mini와 text-embedding-3-small 모델을 활용
- 프롬프트 내 검색된 컨텍스트를 적극 활용
- 질문과 문서 내용을 결합하여 의미있는 응답을 반환



# W2

날짜 : 2025/3/17 ~ 2025/3/21

# 문제 발생

GPT 모델은 OpenAI API를 통해서만 접근이 가능하며, 로컬 환경에서 직접 운영할 수 없다. 로컬에서 직접 사용할 수 있는 오픈소스 모델을 최적화하고, 성능을 개선하는 방법을 모색하였다.

초기에는 Llama-3-70b-Instruction 모델을 채택하여 실험을 진행하였다. 이 모델은 다양한 자연어 처리 태스크에서 우수한 성능을 보이며, 대규모 데이터셋을 기반으로 학습된 강력한 사전학습 모델이다. 그러나, 700억 개의 파라미터를 가진 모델을 로컬 환경에서 그대로 실행하기에는 높은 연산량으로 인해 운영이 어려웠다.

이에 따라 모델의 경량화 및 최적화를 진행했으나, 실험 결과 Llama3-70B-Instruction 모델이 기대만큼의 성능을 발휘하지 못했다. 따라서 대체 모델로 **yanolja/EEVE-Korean-Instruct-10.8B-v1.0**을 채택하여 실험을 진행하였다.

이 모델은 한국어 특화 모델로, 한국어 질의응답 및 문서 요약 등의 태스크에서 우수한 성능을 보인다. 또한 10.8B(108억) 파라미터를 가지고 있어 Llama3-70B보다 상대적으로 가볍고, 로컬 환경에서도 운영이 가능하다.

# 모델 경량화

- 양자화 적용
  - BitsAndBytes : 4-bit 양자화 옵션을 이용해 메모리 효율 향상
  - LoRA : 전체 모델을 미세조정하는 대신 일부 파라미터 학습
    - r : rank를 설정하여 학습해야 할 파라미터 수를 줄임
    - lora_alpha : 적절한 학습 속도를 유지하면서도 학습 효과를 높일 수 있도록 설정
    - lora_dropout : 드랍아웃을 적용하여 과적합 방지
  - GradientAccumulationStep : 모델이 최적의 성능을 내기 위해 필요한 배치 크기가 32라고 했을 때, 해당 옵션을 8로 설정한다면, 32개의 샘플을 8개의 미니배치를 쌓아서 처리한 후 한번에 gradient를 업데이트함.

# MultiQuery

MultiQuery는 하나의 질문에 대해 여러 개의 유사한 질문을 생성하여 검색을 다양화하는 기법이다. 이를 통해 단일 쿼리만 사용했을 때 놓칠 수 있는 중요한 문서를 추가로 검색하며, 보다 풍부한 정보를 기반으로 답변을 생성할 수 있다.

- 입력 질문 변형 : 사용자의 원본 질문을 받아 유사한 질문 5개를 생성한다.
- 질문 변형 후 검색 : 생성된 질문들을 개별적으로 벡터화하여 검색 수행
- 중복 제거 및 상위 결과 선정 : 다중 쿼리로 검색한 결과 중 중복되는 내용을 제거하고 가장 관련성이 높은 문서를 남긴다.

# Rerank

Rerank는 검색된 문서를 다시 평가하여 가장 관련성이 높은 문서를 우선순위로 배치하는 기법이다. ChromaDB에서 기본적으로 유사도 기반 검색을 수행하지만, 추가적인 정렬 과정이 없기 때문에 Rerank를 적용하면 검색된 문서의 품질을 향상할 수 있다.

- 동작 방식
  - 초기 검색 결과 수집 : MultiQuery를 활용해 검색된 상위 n개의 문서를 재정렬
  - Cohere Reranker API를 활용하여 검색된 문서를 재정렬
  - rerank-multilingual-v2.0 모델을 사용
  - Cohere Reranker가 제공하는 점수를 기반으로 문서를 정렬한 뒤, 상위 top_k개의 문서 반환

 

# Few-Shot 예제 추가

```
few_shot_examples = [    {        "question": "차량의 도어가 자동으로 잠기는 조건이 뭐야?",        "answer": "차량의 도어가 자동으로 잠기는 조건은 '차량이 약 13km/h 이상으로 주행 시 자동으로 모든 도어가 잠기게 됩니다'. 이때 강제로 도어 잠금 버튼으로 도어 잠금 상태를 해제하면 도어를 다시 연 후 닫거나 시동을 끄고 다시 시동을 걸지 않는 한 자동 도어 잠금장치는 다시 작동하지 않습니다."    },    {        "question": "스마트키를 실내에 두고 문을 닫으면 어떤 일이 일어나?",        "answer": "스마트키를 실내에 두고 문을 닫으면, '스마트키가 실내에 남아있음을 알리는 기능으로 혼 사운드가 3번 연속으로 울립니다.' 또한, '1개의 스마트 키를 실내에 둔 채로 외부에서 다른 스마트 키를 이용하여 도어를 잠그게 되거나 도어 손잡이의 버튼을 눌러서 잠그면 실내에 있는 스마트 키는 비활성화되어 시동이 불가능합니다.' 이 경우 비활성화 기능을 해제하고자 할 때는 비활성화된 스마트키의 버튼을 누르면 해제가 가능합니다."    },    {        "question": "에어백 점검은 몇년에 한번씩 받아야해?",        "answer": "에어백 점검은 '장착일로부터 10년이 경과하면 반드시 당사 정비망에서 점검을 받으시기 바랍니다.'라고 명시되어 있습니다."    },    {        "question": "임산부는 어떤 안전벨트를 사용해야 해?",        "answer": "임산부는 반드시 3점식 벨트를 착용해야 하며 복부 벨트는 태아를 피해 골반 아래쪽을 지나도록 착용해야 합니다. 이는 충돌 시 태아에 가해지는 압력을 방지하기 위함입니다. 또한, 임신 중 안전벨트 사용 시 주의사항에 대해 의사에게 문의하는 것이 중요합니다."    } ]
```

위와 같은 예제를 프롬프트에 추가해 모델에게 few-shot learning을 시도했지만 프롬프트의 길이가 길어짐과 함께 모델의 성능이 많이 떨어지는 것을 확인했다.

- few-shot 적용 전

```
스마트 키 배터리는 생활폐기물이 아닙니다. 반드시 적절한 재활용 수거장소에 폐기하십시오.
```

- few-shot 적용 후

```
'스마트 키즈침대
```

# 생성 모델 파인튜닝

우선, EEVE 모델을 데이터에 최적화된 모델로 파인튜닝하기 위해, 문서에서 관련된 내용의 질문과 답변쌍을 추출하였다.

```
[    {        "question": "차량의 도어가 자동으로 잠기는 조건이 뭐야?",        "answer": "차량의 도어가 자동으로 잠기는 조건은 '차량이 약 13km/h 이상으로 주행 시 자동으로 모든 도어가 잠기게 됩니다'. 이때 강제로 도어 잠금 버튼으로 도어 잠금 상태를 해제하면 도어를 다시 연 후 닫거나 시동을 끄고 다시 시동을 걸지 않는 한 자동 도어 잠금장치는 다시 작동하지 않습니다."    },    {        "question": "스마트키를 실내에 두고 문을 닫으면 어떤 일이 일어나?",        "answer": "스마트키를 실내에 두고 문을 닫으면, '스마트키가 실내에 남아있음을 알리는 기능으로 혼 사운드가 3번 연속으로 울립니다.' 또한, '1개의 스마트 키를 실내에 둔 채로 외부에서 다른 스마트 키를 이용하여 도어를 잠그게 되거나 도어 손잡이의 버튼을 눌러서 잠그면 실내에 있는 스마트 키는 비활성화되어 시동이 불가능합니다.' 이 경우 비활성화 기능을 해제하고자 할 때는 비활성화된 스마트키의 버튼을 누르면 해제가 가능합니다."    },    {        "question": "에어백 점검은 몇년에 한번씩 받아야해?",        "answer": "에어백 점검은 '장착일로부터 10년이 경과하면 반드시 당사 정비망에서 점검을 받으시기 바랍니다.'라고 명시되어 있습니다."    },    {        "question": "임산부는 어떤 안전벨트를 사용해야 해?",        "answer": "임산부는 반드시 3점식 벨트를 착용해야 하며 복부 벨트는 태아를 피해 골반 아래쪽을 지나도록 착용해야 합니다. 이는 충돌 시 태아에 가해지는 압력을 방지하기 위함입니다. 또한, 임신 중 안전벨트 사용 시 주의사항에 대해 의사에게 문의하는 것이 중요합니다."    },    {        "question": "차량 키를 분실하면 어떻게 해야 하나요?",        "answer": "차량 키를 분실한 경우, 당사 정비망에 문의하여 새로운 키를 등록해야 합니다. 이모빌라이저 시스템이 적용되어 있기 때문에, 새로운 키를 등록하지 않으면 시동을 걸 수 없습니다."    },    {        "question": "스마트 키의 배터리가 방전되었을 때 어떻게 해야 하나요?",        "answer": "스마트 키의 배터리가 방전되면, 기계식 키를 이용하여 운전석 도어를 수동으로 열 수 있습니다. 또한, 스마트 키를 콘솔 위에 올려놓고 브레이크를 밟은 상태에서 시동 버튼을 누르면 시동을 걸 수 있습니다."    },    {        "question": "자동 도어 잠금 장치는 어떻게 작동하나요?",        "answer": "자동 도어 잠금 장치는 차량이 약 13km/h 이상 주행 시 자동으로 모든 도어를 잠급니다. 도어 잠금을 강제로 해제하면 다시 문을 열거나 시동을 끄고 다시 걸지 않는 한 자동 잠금 기능이 재작동하지 않습니다."    },    {        "question": "도난방지 경고 시스템은 어떻게 작동하나요?",        "answer": "도난방지 경고 시스템은 차량이 잠긴 후 30초 후 자동으로 활성화됩니다. 또한, 리모트 키 또는 스마트 키의 잠금 버튼을 눌러 시스템을 수동으로 작동시킬 수 있습니다. 도어가 강제로 열리거나 차량이 움직이면 경보가 울립니다."    },    {        "question": "전동식 유리창이 작동하지 않을 때 어떻게 해야 하나요?",        "answer": "전동식 유리창이 작동하지 않는 경우, 차량 배터리를 확인하고 점화 스위치가 켜져 있는지 확인해야 합니다. 또한, 유리창의 안전 기능이 활성화된 경우 수동으로 조작하여 초기화해야 할 수도 있습니다."    },    {        "question": "스마트 키를 실내에 두고 문을 닫으면 어떤 일이 발생하나요?",        "answer": "스마트 키를 실내에 둔 채로 도어를 닫으면, 경고음이 3번 울리며 키가 내부에 있음을 알립니다. 또한, 외부에서 다른 스마트 키로 문을 잠그면 실내에 있는 스마트 키는 비활성화되어 시동을 걸 수 없습니다."    },    {        "question": "후방 미러의 눈부심 방지 기능은 어떻게 사용하나요?",        "answer": "야간 주행 시 후방 차량의 전조등이 눈부실 경우, 실내 미러 하단의 레버를 조작하여 눈부심을 줄일 수 있습니다. 일부 차량에는 자동 눈부심 방지 기능이 포함되어 있을 수도 있습니다."    },    {        "question": "도어의 어린이 안전 잠금 장치는 어떻게 작동하나요?",        "answer": "뒷좌석 도어의 어린이 안전 잠금 장치는 도어 측면의 레버를 위쪽으로 올려 잠글 수 있습니다. 잠긴 상태에서는 실내에서 도어를 열 수 없으며, 실외에서만 열 수 있습니다."    },    {        "question": "하이패스 시스템이 작동하지 않을 때 어떻게 해야 하나요?",        "answer": "하이패스 시스템이 정상적으로 작동하지 않는 경우, 하이패스 카드가 올바르게 삽입되었는지 확인하고, 카드의 잔액을 체크해야 합니다. 또한, 하이패스 단말기 전원이 켜져 있는지 확인하십시오."    },    {        "question": "에어백 점검은 얼마나 자주 해야 하나요?",        "answer": "에어백 시스템은 장착일로부터 10년이 경과하면 반드시 정비망에서 점검을 받아야 합니다. 에어백 경고등이 점등되거나 에어백 시스템에 이상이 감지되면 즉시 정비소를 방문해야 합니다."    } ]
```

# 생성 결과

추출한 질문-답변 코퍼스를 바탕으로 파인튜닝 시킨 뒤, rerank와 multiquery 기능을 추가한 뒤, 결과는 다음과 같이 출력되었다. 

- 스마트키는 어떻게 버려야해?

```
스마트 키 배터리는 생활폐기물이 아닙니다. 반드시 적절한 재활용 수거장소에 폐기하십시오.
```



- 3점식 벨트에 대해 설명해줘

해당 질문에 대한 답변과 이미지는 문서에 포함된 관련 내용이다.

```
3점식 안전벨트는 어깨와 복부에 걸쳐 착용하는 안전벨트로, 충돌 시 승객을 보호하기 위해 설계되었습니다. 어깨벨트는 어깨에서 반대쪽 골반까지 상체를 가로질러 착용하고, 복부벨트는 골반을 편안하게 감싸주도록 복부 아래쪽에 착용해야 합니다. 3점식 안전벨트는 충돌 시 승객을 제자리에 고정시켜 안전벨트와 에어백의 효과를 향상시킵니다. 안전벨트를 착용하지 않으면 충돌 시 중상을 입거나 사망할 수 있으므로 항상 안전벨트를 착용하는 것이 중요합니다.
```



- 임산부는 어떤 벨트를 사용해야해?

```
임산부는 반드시 3점식 벨트를 착용해야 하며 복부 벨트는 태아를 피해 골반 아래쪽을 지나도록 착용하시기 바랍니다. 이는 충돌 시 벨트가 태아에 가해지는 압력을 방지하기 위함입니다.
```



# 이미지 추출

자동차 메뉴얼은 PDF 형식으로 되어있었으며, 각 페이지에는 차량 부품, 작동 방법 등의 시각적 정보가 포함된 이미지가 존재한다. 관련된 유사한 이미지를 답변으로 얻어내기 위해서는 이를 추출하는 과정이 필요하다. 이를 위해 fitz 라이브러리를 통해 PDF 문서에서 이미지를 탐색하고 추출하는 과정을 진행했다.



# 이미지 캡셔닝(CLIP 파인튜닝용 데이터 구축)

Salesforce/blip-opt-2.7b 모델을 활용하여 자동차 매뉴얼 내 포함된 이미지의 캡션을 생성한 후, 번역 모델을 이용해 영어 캡션을 한국어로 변환한다. 이는 RAG 기반 질의응답 태스크에서 활용될 CLIP 임베딩 모델을 자동차 매뉴얼 데이터에 최적화하기 위한 파인튜닝 데이터 구축 과정이다.



우선, blip-opt-2.7b 모델을 사용한 영어로 번역된 이미지 캡셔닝 결과이다.

## image_2_1.png



![image-20250726144804619](/images/2025-07-24-LLM_W1~4/image-20250726144804619.png)



## 번역 결과

![image-20250726144839868](/images/2025-07-24-LLM_W1~4/image-20250726144839868.png)

## 번역 결과 정제 및 보완

자동 생성된 이미지 캡션은 이미지의 내용을 대략적으로 설명하는는데 유용했으나, 다음과 같은 문제가 있었다.

- 일부 설명이 모호하거나 불완전한 표현
- 실제 이미지와 다른 내용 포함
- 한국어 번역 과정에서 의미가 부정확하게 표현됨

최적화된 임베딩 모델을 구축하기 위해 이미지를 하나씩 대조하며 캡션을 수정하는 작업을 수행하였다.

- 잘못된 설명을 수정하고 직관적인 용어로 변경
- 불완전환 설명 보완
- 이미지 내 명확한 특징 반영



# 이미지 출력 결과 확인

```
답변: 스마트 키 시스템에서 차량 내부에 키가 남아 있는 상태에서 도어를 잠그면, 해당 스마트 키는 비활성화되어 시동이 불가능해집니다. 비활성화 기능을 해제시키고자 할 때는 비활성화된 스마트 키의 버튼을 누르면 해제가 가능합니다. 가장 관련 있는 이미지: ./image/image_65_2.png
```



유사한 이미지를 출력한 결과를 확인했지만, 질문과 전혀 관련이 없는 이미지를 반환하는 문제가 발생했다. 기존의 코사인 유사도 기반 검색 방식을 보완하기 위해 코사인 유사도와 유클리드 거리를 결합한 유사도 계산 방식을 도입했다. 추후에는 마할라노비스, Jaccard 유사도 등 더 나은 결과를 위해 실험을 할 계획이다.

## 유사도 계산 로직 수정

- 코사인 유사도
  - 벡터 간의 방향적 유사도를 측정
  - 값이 1에 가까울수록 유사
- 유클리드 거리
  - 벡터 간의 거리 차이를 측정하여 유사성을 보완
  - 값이 작을수록 더 유사
- 수식

```
score = (0.7 * cosine_sim) - (0.3 * (euclidean_dist / 100))
```

## 핵심 키워드 반영 로직

- 키워드 추출
  - Spacy를 이용해 질문의 핵심 키워드 추출
  - 예 : “스마트키 배터리 교체 방법” => [“스마트키”, “배터리”]
- 가중치 부여
  - 추출된 핵심 키워드의 임베딩 추출
  - 원본 데이터와 키워드 데이터에 가중치를 부여한 뒤, 가중합

```
  weighted_embedding = (0.7 * main_embedding) + (0.3 * keyword_embedding)
```

# 환각 방지(검증용 LLM)



LLM의 응답은 때때로 출처가 명확하지 않거나 문서에 존재하지 않는 정보를 마치 있는 것처럼 생성하는 문제가 발생함. 이를 방지하기 위해 문서에서 검색된 내용(context), 사용자 질문(query), 생성용 LLM의 답변(answer)을 input으로 받는 또다른 검증용 LLM을 도입했다.

- 적용 방식
  - 메인 LLM은 사용자의 질문과 문서를 바탕으로 응답 생성
  - 검증 LLM은 메인 LLM의 응답을 문서와 비교하여 검증 결과 생성
- 모델
  - 검증 LLM으로 사용한 모델은 dntitia/DNA-R1 모델로 추론 모델인 DeepSeek R1 모델을 기반으로 한 한국어 모델로, 한국어 추론에 뛰어나다

# W3

기간 : 2025년 3월 24일 ~ 2025년 3월 28일

# 3/24

# 목표

W2의 실험에서 검증용 LLM으로 사용한 DNA-R1 모델이 예상과 달리 검증 결과를 아예 출력하지 않거나 말이 되지 않는 문장을 생성하는 문제가 발생했다. 이는 문서에서 적절한 근거를 찾지 못하거나, 검색된 문서의 품질이 낮은 경우, 또는 프롬프트가 불완전한 경우로 추정된다.

따라서 이번주차에는 문서 기반 근거 확보 정확도 향상 및 검증용 LLM의 안정성을 향상하고자 한다.

# Semantic Chunking

기존에는 일정 길이 단위로 문서를 분할 => 속도는 빠르지만, 문장의 의미 단위가 보장되지 않았고, 중요한 내용이 올바르게 담기지 않는 단점이 있음

- 개선 사항
  - SentenceTransformer 기반으로 문장을 의미 벡터로 임베딩
  - 의미적으로 밀접한 문장들을 하나의 청크 => 정보의 완결성
  - 청크의 유사도 임계값(threshold)과 최대 길이(max_chunk_size)를 조절 가능

# Hybrid Search

기존에 CLIP 기반 임베딩의 코사인, 유클리드 유사도를 혼합해 검색했지만, 이는 키워드 기반 쿼리에 취약하고 잘못된 문맥이 높은 점수로 랭킹되는 문제점이 있었음

- 개선 사항
  - 유사도 기반 검색 결과에 대해 추출한 키워드와의 매칭 점수를 별도로 계산
  - 최종 점수 = w2 * 유사도 점수 + w1 * 키워드 점수로 가중 합산 
  - 키워드 추출은 Okt()를 사용해 사용자의 주요 명사를 분석하여 반영

# Query Rewrite

실제 사용자의 질문은 “하이패스가 갑자기 안돼요” 와 같은 비정형 표현이 많음. 이를 해결하기 위해 Query Rewrite 기법을 도입

- 개선 사항
  - EEVE 모델을 활용하여 입력 쿼리를 검색 친화적 표현으로 변환 
  - “앞유리에 김 서리는거 어케함” => “앞유리 김 서림 원인과 제거 방법”
  - 재작성된 쿼리를 바탕으로 유사 문서 검색 정확도 향상

# 결과

- before



- after



적용 이전의 경우, 문서가 장황하게 검색되었을 뿐 아니라, 정답 문장도 불완전하게 포함되어 정답을 제대로 생성하지 못한 반면, 적용한 이후에는 정답 문장을 포함하고 훨씬 간결해졌다.

# 3/25

# 목표

본 실험은 RAG 시스템에서 생성 및 검증 텍스트 정확도 향상을 위해 모델 파라미터, 가중치 및 프롬프트 구성을 조정하고, 그 효과를 평가하고자 수행되었다.

# 모델

- 생성용 LLM : heegyu/EEVE-Korean-Instruct-10.8B-v1.0-GGUF
- 검증용 LLM : dnotitia/DNA-R1

# 조정한 파라미터 항목

- max_new_tokens
  - 모델이 한번에 생성할 수 있는 최대 토큰 수
  - 영향 : 너무 작으면 불완전한 응답, 너무 크면 불필요한 문장 생성, 반복
- temperature
  - 출력 확률 분포의 무작위성을 조절하는 값. 0에 가까울수록 결정적, 1에 가까울수록 창의적인 결과가 나옴
  - 문서를 기반으로 정확한 정보 위주의 응답을 해야함 => 0.5 미만의 값 적용
- top_p
  - 전체 확률 분포 중 상위 p 누적 확률을 가진 단어들만 선택지로 제한
  - 불필요한 단어가 출력되는 현상 방지
  - 0.7~0.9 적용
- repetition_penalty
  - 동일하거나 유사한 단어 반복을 제어
  - 값이 클수록 유사한 단어나 문장을 반복하지 않는다
  - 1.1~1.5 적용
- early_stopping
  - 모델이 응답이 끝났다고 판단하면 즉시 중단
  - 과잉 생성 방지, 응답 길이 제어

# 파라미터 조정

- 답변 제약조건 : “문서 내용이 관련 없을 경우 답변하지 말 것”과 같은 룰
- [답변 시작] 이후에만 답변이 생성되도록 유도
- 답변 형식, 출력 포맷 조정

# 문제

- 검증용 LLM
  - 아무 결과도 나오지 않음
  - 문장을 제대로 마치지 못함
    - `문서 기반 근거에 따르면 트렁크 열림 및 닫힘 문제는 '키, 도어 및 유리창'  섹션에서 다루고 있습니다. 특히 리모트 키(리모컨) 관련 내용이 7페이지에 위치해 있으며,  트렁크 문제의 원인으로 리모컨의 역할을 언급할 가능성이 있습니다.  그러나 LLM 답변에서는 "문서에 따르면, 트렁크 열림과 닫힘은 키, 도어 및 유리창 섹션에  설명되어 있습니다. 트�`
  - 아는척
    - `신뢰할 만한 출처를 찾았습니다! 해당 내용은 다음과 같습니다...`
  - 프롬프트 반복
    - `[LLM 답변]은 [문서 기반 근거]의 정보와 일치합니다. 문서에서 언급된 도어 잠금 해제 방법인 잠금 버튼 사용 또는 점화 스위치를 LOCK 위치로 전환하여 잠금을 해제하는 내용을 정확히 반영하였습니다. 또한, 수동 해제 후 AUTO 복귀에 대한 설명도 문서 내용과 일치합니다. 따라서 LLM 답변은 신뢰할 수 있는 것으로 판단됩니다.    ### 사용자 질문:    뒷문 애가 안에서 못 열던데 잠금 돼있나?    ### 변환된 �`
- 생성용 LLM
  - 아무 결과도 나오지 않음
  - 환각(문서에 없는 내용)
    - `네, 일부 현대식 차량들은 '스마트' 혹은 '보이스 컨트롤'이라고 불리는 고급 기능과 안전 기술을 제공합니다. 이러한 기술들 중에는 특정 상황에서 차량 문의 개폐 상태를 감지하거나 조정하는데 도움을 주는 다양한 센서와 전자 구성요소가 포함되어 있죠. 예를 들어, 어떤 모델들의 경우 차가 출발하면서 뒤따르는 물체를 인지하게 되면 스스로 문을 열기도 하고, 반대로 차를 주차시키면서 주변 장애물을 인식하고 적절히 대응하기도 하죠. 하지만 이런 기술은 제조사마다 다를 수 있고 모든 차량이나 트림 레벨에 제공되는 것은 아닙니다. 또한 언급하신 바와 같이, 대부분의 최신 차량들이 가지고 있지 않은 추가적인 특징이기도 해요. 만약 귀하께서 소유하시는 차량에도 이와 유사한 기술이 적용되었다면, 이는 보통 인포테인먼트 디스플레이나 헤드업 디스플레이(HUD) 형태로 정보를 제공하고 필요할 때는 시각적인 경고나 소리를 통해 알려줍니다.`
  - 질문 반복
    - `비상시 문 여는 거 그 뭐냐 스마트키 없어도 되는 거    문서에 따르면, 스마트 키가 작동하지 않거나 수신 범위 밖에 있을 경우, 차량 내 키 회수 알림 기능이 작동하여 혼 사운드가 3번 연속으로 울립니다. 이 기능은 스마트 키를 차량 안에 두고 나갔을 때 운전자가 이를 인지할 수 있도록 도와줍니다. 스마트 키가 작동하지 않거나 수신 범위 밖에 있을 경우, 차량 내 키 회수 알림 기능이 작동하여 혼 사운드가 3번 연속으로 울립니다. 이 기능은 스마트 키를 차량 안에 두고 나갔을 때 운전자가 이를 인지할 수 있도록 도와줍니다. 스마트 키가 작동하지 않거나 수신 범위 밖에 있을 경우, 차량 내 키 회수 알림 기능이 작동하여 혼 사운드가 3번 연속으로 울립니다. 이 기능은 스마트 키를 차량 안에 두고 나갔을 때 운전자가 이를 인지할 수 있도록 도와줍니다. 스마트 키가 작동하지 않거나 수신 범위 밖에 있을 경우, 차량 내 키 회수 알림 기능이 작동하여 혼 사운드가 3번 연속으로 울립니다.`
  - 검색된 문서 그대로 사용
    - `검색된 문서 내용 : 1. 딩동 발급일은 입니다. 발급 후 사용하십시오. 발급 후 사용 하십시오. 발급 후 사용 하십시오. 질문 : 우주에서 제일 험한 환경인 별 어딘지 아는 사람?? 완전 미친 조건인 별    당신은 자동차 설명서를 기반으로 질문에 답하는 AI 어시스턴트입니다. 사용자 질문과 문서를 참고하여 정확한 답변을 제공하세요. 문서에 질문과 관련된 답변이 없다면, "관련된 내용을 찾을 수 없습니다"라고 출력하세요.`
    - `[문서 일부] 1. 딩동 발급일은 입니다. 발급 후 사용하십시오. 발급 후 사용 하십시오. 발급 후 사용 하십시오. `

# 결과

파라미터와 프롬프트를 조정하며 실험을 진행했지만, 오히려 품질이 떨어졌다.

```
[답변] 당신은 자동차 설명서 내용을 기반으로 답변하는 AI 어시스턴트입니다. [문서] 딩동 발급정보가 없습니다. 비활성화를 해제하려면 Q와 K 버튼을 다시 약 3초간 동시에 누르십시오. 발급 후 사용하십시오. 이 기능은 틸트 올 리기닫기에도 동일 적용됩니다. 발급 후 사용 하십시오. [질문] 인간의 기억을 디지털 형태로 저장하고 복원하는 것이 가능할까요? 다음 규칙을 반드시 지키세요: 1. 문서에 질문과 관련된 정보가 있는 경우에만 답변하세요. 2. 문서에 해당 정보가 없거나 관련성이 명확하지 않으면, 반드시 아래 문장을 단독으로 출력하세요: 관련된 내용을 찾을 수 없습니다 3. 문서 외 지식이나 상식, 추측은 절대 사용하지 마세요. 4. 질문을 반복하거나 요약하지 마세요. 5. 아래에 답변만 작성하세요. [검증 결과] 
[답변] [검증 결과] <think> Okay，我现在要检查LLM的回答是否基于提供文档内容可靠。用户问了关于Hi-pass终端机红单色灯亮起时可能出错代码是什么？ LL M给出几个错误码：E01、C02等，并列举多种原因。 首先需要确认这些误差代号和情况对吗？ 根据参考资料中“非正常状态”部分，“未注册设备”， “卡片尚无挂入”, "使用不当之类"都会导致单领点亮。“余额低至20元以下（D06）",还有高速过路口通行期间故障"F07”。而列表里L LM 提到如下： - 没有注册 终端器 （Error code:E01） - 卡没有插入(Code:C02)， 使用禁止性质 的card 插入后 Code为C03； 进展例外但有效日期已满则Code=E04 ，序號錯誤編碼E05 等。 然後還包括體額少於２０００日圓時 D06 和 高速運転途間當機能失效 F07  看来參考文件裡面确实涵盖所有所舉給用者解釋清楚每個code 对应哪種問题。例如：“non-registration device”的话就會显示紅點以及相關error codes比方说E01或其他相关项目，在資源內容也明示此事項。同样地像沒投注金幣 尺寸 或許無法辨識 card 版权问题等均被覆蓋其中。 再次核對詳述段落："Non-normal status red light illumination includes unregistered devices, no-card insertion scenarios leading to error like 'Card not inserted' with specific codings such as C02 or others mentioned." 所见与LLMs 图示一直保持契合度很好。。 唯一需注意的是某些描述词汇匹配程式上正确储存否定反映结果符合条件即使存在重复说明 如何处理呢?
```

# 3/26

# 목적

- 보유 중인 GPU 환경에서 다양한 대규모 언어 모델의 실행 가능성 및 응답 시간 성능을 평가.
- 프롬프트 및 하이퍼파라미터 조정 과정에서 있었던 응답 품질 저하 해결

# GPU 실험

검증용 LLM은 DNA-14B 사용

- heegyu/EEVE-Korean-Instruct-10.8B-v1.0-GGUF => O(3~5분 소요)
- Qwen/Qwen2-72B-Instruct => O(4~7분 소요)
- HuggingFaceM4/idefics-80b-instruct
- meta-llama/Llama-3.2-90B-Vision-Instruct
- moreh/Llama-3-Motif-102B-Instruct => O(7~10분 소요)

# 하이퍼파라미터

## top_p : 0.9 => 0.7

top_p 파라미터는 모델이 다음 토큰을 고려할 때 고려하는 확률 분포의 누적 확률 상한을 의미함.

top_p의 값이 크면 창의적인 답변, 작으면 결정적인 답변을 함. top_p 파라미터가 너무 크게 설정되어 있어서 작게 수정함. 

## do_sample=True

do_sample은 텍스트 생성 시 다음 단어를 확률 분포로부터 무작위로 선택할지 결정하는 옵션이다.

- True : 확률 분포 기반 샘플링 수행
- False : 확률이 가장 높은 단일 토큰 선택

# 프롬프트 조정

LLM별로 최적의 프롬프트 포맷을 적용함으로써, 출력 결과의 신뢰도를 개선하고, 문서 기반 질의응답에서의 성능을 안정화하기 위해 프롬프트 조정을 했다. 특히, llama3-motif-102b와 DNA-R1 두 모델에 대해 알맞은 프롬프트 형식을 탐색하여 적용하였다.

## Llama3-motif-102b

Llama3 공식 문서에는 <|system|>,<|user|>, <|assistant|> 태그를 사용하라고 명시되어 있었지만, 외국어가 출력되는 등 문제가 발생했다.

```
prompt = f"""A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. Human: 다음은 자동차 설명서의 일부입니다. 반드시 이 문서를 참고해 질문에 답해주세요. 문서에 관련 내용이 없다면, 반드시 답변할 수 없다고 답변하세요. 반드시 한국어로 답변하고, 문서에 기반해서 답변하세요 [문서] {context} [질문] {transformed_query} Assistant:"""
```

“Human: “, “Assistant: “와 같이 role을 명확하게 구분해주는게 핵심이었다.

## DNA-R1

```
prompt = f"""USER:        ---        문서 내용: {context}        질문: "{preprocessed_query}"에 대한 아래 LLM 답변은 문서에 근거한 신뢰할 수 있는 답변인가요?        LLM의 답변: {answer}        LLM의 답변이 문서와 관련 없는 경우에도, 그 이유를 설명하고 낮은 점수를 부여하세요.        전문가로서 판단해 주세요. 아래 형식을 따르세요.         <think>문서와 비교해 근거, 누락 여부, 정확성을 설명</think>          <answer>0에서 100 사이의 신뢰도 숫자만</answer>        ASSISTANT:"""
```

# 결과

```
[답변] 문서에 제공된 정보로는 도난 방지 시스템의 오작동 해결 방법에 대한 직접적인 언급이나 지침이 없습니다. 하지만 '시스템의 오작동 우려가 있으므로 운영자가 임의로 조작하지 말라'라는 문장이 두 번 강조되어 있는  것으로 보아, 문제 발생 시 전문가나 서비스 센터의 지원을 받도록 권장되고 있을 가능성이 높습니다. [검증 결과] <think> 문서 내용을 분석해야 합니다.  1. **도난방지 장치 관련 정보**: 문서 시작 부분에 "그리고 도난방지 장치가 작동됩"니다."라고 되어있습니다. 이는 도난방지 시스템이 활성화되었음을 알립니다.  2. **시스템 오작동 주의사항**: 문서 내 여러 위치(주의)에서 "시스템의 오작동 우려가 있으므로 운전자가  임의로 조작하지 마십시오."라고 명시되어 있습니다. 이는 사용자가 직접 시스템을 조작해서는 안 된다는  경고입니다.  3. **리셋 방법 관련 내용**: 문서 내에서 도난방지 시스템의 오작동을 해결하는 방법이나 리셋 절차에 대한 구체적인 지침은 찾을 수 없습니다. 예를 들어, 버튼 조작이나 설정 변경 같은 단계가 언급되지 않았습니다.  4. **LLM의 답변 평가**: LLM은 문서에 직접적인 해결 방법이 없으므로 전문가나 서비스 센터의  도움을 권장한다고 결론 내렸습니다. 이는 문서의 반복적인 주의사항("임의 조작 금지")과 일치합니다.  **결론**: 문서에는 도난방지 시스템 오작동 시 사용자 스스로 조치하는 방법이 없으며, 외부 지원 필요성을 암시합니다. 따라서 LLM의 답변은 문서에 근거한 신뢰할 수 있다고 판단됩니다. </answer> <answer> 문서에는 도난방지 시스템 오작동 시 사용자가 직접 조작하지 말라는 경고가 반복되지만, 구체적인 리셋 방법은 명시되지 않았습니다. LLM은 이를 바탕으로 문제 해결을 위해 전문가나 서비스 센터의 도움을 권장하는 답변을 제시했으며, 이는 문서의 내용과 일치합니다. 따라서 해당 답변은 문서에 근거한 신뢰할 수 있는 것으로 판단됩니다. - **근거**: 문서 내 "시스템 오작동 우려" 및 "임의 조작 금지" 경고 → 사용자 개입 배제 - **누락/정확성**: 리셋 절차 미기재 → 외부 지원 필요성 함의 신뢰도: 85 (문서의 경고 메시지와 LLM의 결론이 일치하나, 구체적 절차 부재로 인해 완전한 확신은 낮음) </answer>
[답변] 문서에는 사람의 기억과 컴퓨터 기술에 대한 직접적인 정보가 제공되지 않습니다. 따라서 해당 주제와 관련하여 명확한 답변을 드릴 수가 없습니다.
```

# 3/27

# 목적

기존에 개발한 RAG는 질문 처리, 문서 검색, 문맥 구성, LLM 응답 생성이 하나의 파이프라인에 얽혀있어 유지보수가 어렵다. MCP 도입을 통해 검색(MCP 서버)과 응답 생성 로직(MCP 클라이언트)을 분리함으로써, 각 구성요소를 독립적으로 개발할 수 있는 구조를 만드는 것이 목적이다.

# 시스템 흐름

```
┌──────────┐
│     PDF 문서       │
└────────┬─┘
         │
         ▼
┌────────────────────┐
│ 텍스트, 이미지 추출 │  ← (fitz, PIL)
└────────┬───────────┘
         │
         ▼
┌────────────────────────────┐
│ 문장/청크 단위로 분할 및 전처리 │  ← (의미 기반 chunking)
└────────┬───────────────────┘
         │
         ▼
┌────────────────────────────┐
│ 텍스트/이미지 임베딩 생성     │  ← (SentenceTransformer, CLIP)
└────────┬───────────────────┘
         │
         ▼
┌───────────────┐
│ 벡터 DB 저장 (Chroma 등)     │
└────────┬──────┘
         │
         ▼
┌─────────────────┐
│     MCP Server (FastAPI)         │
│ - 유사 문서 검색 (벡터 + Rerank) │
└────────┬────────┘
         │
         ▼
┌───────────────┐
│   검색된 문서 Context 반환   │
└────────┬──────┘
         │
         ▼
┌────────────────────────────┐
│        LLM 응답 생성        │  ← (LLaMA3-Motif)
└────────┬───────────────────┘
         │
         ▼
┌────────-─┐
│  답변 검증 LLM    │
└────────-─┘
         │
         ▼
┌───────────────┐
│        최종 Output 출력      │
└───────────────┘

```

# 파일구조

```
project_root/
├── mcp_client/
│   ├── query_handler.py         # 사용자의 질문 분석, 서버 호출, 응답 포맷팅
│   └── __init__.py
│
├── mcp_server/
│   ├── server.py                # FastAPI 서버: 쿼리 받아서 문서 검색, 변환 등 처리
│   ├── pdf_indexer.py           # PDF 문서 벡터화 및 Chroma에 저장
│   └── __init__.py
│
├── llm/
│   ├── answer_generator.py      # LLM 추론
│   ├── verifier.py              # 검증 LLM (정답 신뢰도 판단)
│   └── __init__.py
│
├── image/
│   ├── clip_handler.py          # 이미지 검색
│   ├── cache/                   # 이미지 임베딩 캐싱
│   └── images/                  # 실제 이미지 파일들
│
├── data/
│   └── maintenanceSample.pdf               # 예시 PDF 파일 (자동차 매뉴얼 등)
│
├── chroma_db/                  # ChromaDB의 저장 디렉토리
│
│
└── main.py                     # main
```

# MCP 결과

- 도난방지인가 그거 울리는데 끄는 거 어케 함?

```
답변 :  도난 방지를 해제하려면 차량 리모컨을 이용하여 잠금 버튼과 열림 버튼을 동시에 누르십시오. 이렇게 하면 경보음이 꺼지고 도난 방지가 해제됩니다. 검증 결과 :  
```

# 향후 개선 사항

- Context Compression : 검색된 청크 수가 많을 경우, 요약 모델을 통해 핵심정보 압축
- Kmeans Clustering : 유사한 청크끼리 묶어 대표문서만 선택, 압축하여 저장
- Meta data : 메타 데이터를 통해 출처 명시
- 이미지 : 이미지 설명 → 임베딩 방식으로 변경

 # W4

날짜 : 3/31 ~ 4/4

#  3/31

# 목적

기존 벡터 검색기반 문서 Q&A 시스템에서 사용자 질문에 대해 관련 문서를 검색하고 응답을 생성하였으나, 답변에 사용된 문서의 출처를 명시하지 않아 신뢰도가 떨어지는 문제가 있었다.

이에 따라, 각 텍스트 청크에 출처 정보를 메타데이터로 저장하고, 검색 시 이를 참조하여 답변에 포함시키는 기능을 추가하였다.

# PDF 처리 시 메타데이터 저장

- PDF 처리 시 메타데이터 저장 : process_pdf()
  - PDF를 페이지 단위로 읽고, 각 페이지에서 텍스트를 분할한 후 청크별로 해당 파일명과 페이지 번호를 메타데이터로 포함시킴
  - `metadata = {                "text" : chunk,                "source" : os.path.basename(pdf_path),                "page" : page_num            }`
- 검색 시 메타데이터 참조 : get_topk()
  - 검색된 문서 청크에서 source와 page를 추출하여 결과와 함께 반환
  - `topks.append({                "id": results["ids"][0][i],                "text": text,                "score": hybrid_score,                "source" : metadata.get("source", "unknown"),                "page" : metadata.get("page", "?")            })`
- Context 생성시에도 출처를 함께 표시 : generate_response()
  - LLM이 생성한 응답에서 실제로 참조된 문서의 출처를 명확히 명시할 수 있게 되어 답변에 대한 신뢰도 상승
  - `context = "\n".join([        f"(출처 : {doc.get('source', 'unknown')}, 페이지 : {doc.get('page', '?')})\n{doc['text'][:1024]}"        for doc in relevant_chunks        ])`
- 결과 예시
  - `[질문] 눈 많이 오는데 어떻게해야하냐 [답변] (출처 : maintenanceSample.pdf, 페이지 : 46) 주기적으로 선 루프 유리 고무와 차체 사이의 먼지를 제거하십시오. 동결 및 눈이 덮여 있을 때 선 루프를 열면 유리 또는 모터가 손상 될 수  있습니다. 우천시나 세차 직 후에 선 루프를 열면 실내로 물이 유입될 수 있습니다.`
  - `maintenanceSample.pdf의 3페이지에 따르면, 열선 버튼은 누르면 작동되며 일정 시간이 지나면 자동으로 꺼집니다...`

# 메모리 누수

프로그램의 과도한 메모리 사용 및 성능  저하 문제를 해결하기 위해, 코드 구조를 최적화시켰다.

1. SentenceTransformers 모델 초기화 위치 수정

- 기존 문제 : SentenceTransformers(model_name) 객체가 함수 내부에서 매 호출마다 반복 생성되어 불필요한 연산 및 메모리 낭비가 발생
- 모델 초기화 코드를 함수 외부로 이동시켜 한 번만 로딩되도록 하여 성능 향상 및 리소스 절약

1. 벡터DB 접근 방식 개선

- 기존 문제 : 청크별로 매번 DB에 접근해 add() 호출을 반복하였고, 성능 저하의 원인이 되었다.
- 개선 조치 : 모든 임베딩과 메타데이터를 리스트에 append()로 수집한 뒤, 한번만에 DB에 일괄 저장하도록 변경

1. 임베딩 데이터 타입 최적화(float32 → float16)

- 기존 문제 : CLIP 임베딩 결과를 기본 데이터 타입인 float32로 저장하여 불필요한 메모리 사용량 증가
- 개선 조치 : 임베딩 결과를 float16으로 변환하여 저장

1. 명시적 메모리 해제

- 기존 문제 : 반복문 내에서 생성된 임시 변수들이 메모리에 계속 유지되어 누적 사용량 증가
- 개선 조치 : del 키워드를 통해 불필요한 변수의 참조를 명시적으로 해제, gc.collect()를 호출하여 가비지 컬렉션을 수동 실행함.
- 파이썬은 자동으로 알아서 정리하지만, 대용량 객체를 반복 생성, 삭제할 때는 수동으로 실행하는 것이 안정적이다.

 

# 4/1

# 목적

- K-means clustering을 통해 유사한 임베딩을 사전에 군집화하여, 검색 시 특정 클러스터만 조회함으로써 검색 속도 향상 및 품질 개선
- LLM에게 좋은 답변, 나쁜 답변 예시를 구조적으로 추가함으로써, 문서 기반 답변이라는 목적과 판단 기준을 명시하여 답변의 신뢰성과 정당성 확보

# K-means clustering

- 적용 방식
  - PDF 청크들에 대해 클러스터의 갯수 수동으로 적용(k=2~8)
  - silhouette_score를 통해 최적의 군집 수를 계산
  - 위 두가지 방법으로 적용 후 VectorDB에 저장
- 결과

문서와 관련 없는 질문에 대해서는 환각현상이 줄어드는 것처럼 보였으나,

```
[질문] 배불러서 잠오는데 어떻게해야되냐 [문서 일부] (출처 : maintenanceSample.pdf, 페이지 : 11) 주의 (출처 : maintenanceSample.pdf, 페이지 : 59) 충 격을 받아 갈기갈기 찢어질 수 있습니 다. (출처 : maintenanceSample.pdf, 페이지 : 12) 이 상태로 아무 조치를 하지 않을 경우 약 5분 후에 자동으로 OFF 됩니다. (출처 : maintenanceSample.pdf, 페이지 : 35) 딩동 발급일은 입니다. (출처 : maintenanceSample.pdf, 페이지 : 35) 딩동 만기일은 입니다.
```

문서에 있는 내용임에도 불구하고, 오히려 검색 성능이 떨어졌다.

```
[질문] 차키 배터리 다된것같은데 뭔배터리 사야되냐 [문서 일부] (출처 : maintenanceSample.pdf, 페이지 : 63) 이때 점화장치가 켜져 있어야 합니다. (출처 : maintenanceSample.pdf, 페이지 : 80) 작동 시 버튼을 다시 누르면 소등됩니 다. (출처 : maintenanceSample.pdf, 페이지 : 80) 10 개요  비상 경고등 버튼을 눌러서 작동합니다. (출처 : maintenanceSample.pdf, 페이지 : 78) 보조장치  20. (출처 : maintenanceSample.pdf, 페이지 : 61) 자극이 계속되면 의 사와 상의하시기 바랍니다.
```

 

# Contrastive In Context Learning

- 논문 소개

[Enhancing Retrieval-Augmented Generation: A Study of Best Practices](https://arxiv.org/abs/2501.07391)

위 논문은 RAG에 관한 여러가지 테크닉을 적용해보고, 어떤 방법이 효과적이었는지 기술된 논문이다. 해당 논문에서, **Contrastive In Context Learning**이라는 LLM에게 좋은 답변, 나쁜 답변 예시를 함께 제공함으로써 성능이 월등하게 높아졌다는 결과를 내세웠다.

- 예시 구조
  - 검색된 문서의 출처 인용 강제
  - 검색되지 않은 내용에 대해서는 찾을 수 없다라는 답변을 하도록 강제
  - 검색된 내용을 인용하도록 강제
- 적용 프롬프트

```
  System: 당신은 자동차 설명서를 바탕으로 질문에 답변하는 전문 상담원입니다. 문서에 나와 있지 않은 정보는 절대 답변하지 마세요. 아래는 문서를 참고하여 적절하게 답변한 예시와, 문서에 없는 내용을 사용해서 잘못 답변한 예시입니다: --- 좋은 답변: [문서] (출처 : manualA.pdf, 페이지 : 12) 시동 버튼은 브레이크를 밟은 상태에서 눌러야 작동됩니다. [질문] 시동 버튼은 어떻게 작동되나요? [답변] (출처 : manualA.pdf, 페이지 : 12)에 따르면, 시동 버튼은 브레이크를 밟은 상태에서 눌러야 작동됩니다. --- 좋은 답변: [문서] (출처 : manualB.pdf, 페이지 : 45) 주행 중 전방 충돌 경고 시스템이 작동합니다. [질문] 에어백은 언제 작동하나요? [답변] 문서에서 에어백과 관련된 내용은 찾을 수 없습니다. --- 나쁜 답변: [문서] (출처 : manualB.pdf, 페이지 : 45) 주행 중 전방 충돌 경고 시스템이 작동합니다. [질문] 에어백은 언제 작동하나요? [답변] 에어백은 보통 충돌 시 자동으로 작동합니다. (문서에 해당 내용 없음) --- 아래는 당신이 참고할 문서와 질문입니다. 문서를 바탕으로만 답변하고, 반드시 출처를 포함해주세요. [문서] {context} [질문] {query} [답변] Assistant : 
```

- 생성 결과

```
[질문] 도난방지 경고 어떻게 끄냐 [답변] (출처 : maintenanceSample.pdf, 페이지 : 24) 도난 방지 경고 시스템은 리모콘 키의 잠금 또는  해제 버튼을 누르거나 점화 장치를 켬으로써 해제 할 수 있습니다.
[질문] 배고픈데 어떻게하냐 [답변] 문서에서 '배' 또는 '고픔'이라는 단어가 들어가는 문장은 다음과 같습니다:  - 선 루프 가 열린 상태에서는 선 블라인드 도 항상 열려 있습니다.  - 우 천 시 나 세 차 직 후 에 선 루프 를 열 면 실 내 로 물 이 유 입 될 수 있 습 니 다. 그러나 구체적인 방법론 제시는 되어 있지 않습니다. 따라서 문서에 있는 그대로 답변이 불가능하며, 추가적인 자료 없이 추측 또한 금지되어 있습니다.
```

# 개선사항

- 문서에 포함되지 않은 질문의 케이스에서 프롬프트 실험을 통해 개선 예정

# 4/2

# 목적

- 코드 유지보수성 향상, 기능 단위 분리를 위한 모듈화 진행

# 모듈화

- 주요 개선 사항
  - 모듈화 이전에는 모델 중복 로딩 문제
  - 전역 _model, _tokenizer 사용
  - 모델 로딩 단일화 : 응답 생성 시간 약 5 ~ 10분 → 약 2분
- 이미지 임베딩 로직 변경
  - before : 이미지 자체의 유사도를 측정하려 했으나, 정확도 및 유사도 판단 한계
  - 이미지에 설명 텍스트를 부여한 뒤, 텍스트 임베딩 모델로 임베딩

# 이미지-설명쌍 데이터 구축

# 목적

- 사용자의 질문에 대해 가장 유사한 이미지를 제공하기 위해, 이미지에 적절한 설명을 부여하고, 이를 임베딩하여 검색 가능한 형태로 변환하는 이미지-텍스트 쌍 데이터 구축

# 구축 방식

1. 설명 문장 생성 기준

- 사용자의 질문에 등장할 법한 키워드 포함
- 이미지가 등장한 페이지에 포함된 문장 포함
- 설명은 행동, 기능 중심 표현으로 작성
  - `"스마트키를 몸에 지닌채로 문을 열어야 함"`
  - `"스마트 키를 콘솔에 올려야 시동이 걸림"`
  - `"실내에서 문을 열기위한 레버"`



 

# 이미지 설명 임베딩 후 검색 결과

```
[질문] 하이패스에서 카드를 확인하십시오라는 소리가 나는데 이거 왜이런거야 [이미지] ('./image/image_30_1.png', '하이패스 시스템 미러. 카드 빼는법, 프로그램 입력단자')
[질문] 시트 높이조절 어떻게하냐 [이미지] ('./image/image_52_2.png', '시트 높이 조절')
```

기존의 멀티모달 임베딩 모델을 활용했을 때, 질문과 관련된 이미지를 출력하지 못하고 같은 이미지만 출력하는 현상이 발생했지만, 이미지에 대한 설명을 임베딩 후 검색을 진행하니 훨씬 나은 결과가 나왔다.

# 4/3

# 프롬프트 개선

모듈화를 진행하기 전에는 특정 프롬프트를 사용했을 때 우수한 응답 품질을 확인할 수 있었다. 하지만 모듈화를 진행한 이후, 동일한 프롬프트를 사용했음에도 불구하고 아무런 응답을 출력하지 않는 문제가 발생했다.

# 문제 현상

- LLM이 응답을 생성하지 않음
- 출력된 토큰의 ID를 확인해보니 EOS 토큰 하나만 반환

# 원인 분석

- 모델 로드는 정상적으로 이루어졌고, 다른 프롬프트를 사용했을 때 출력이 잘 이루어짐
- 모듈화를 진행하는 과정에서 .txt파일로 변경
- 기존의 프롬프트와 차이점은 프롬프트 마지막줄 개행문자 유무

# 결과

- Before

```
[질문] 시트 높이조절 어떻게하냐 [답변] 
```

- After

```
[질문] 도난방지 경고 어떻게 끄냐 [답변] (출처 : maintenanceSample.pdf, 페이지 : 24) 도난 방지 경고 시스템은 리모콘 키의 잠금 또는 해제 버튼을 누르거나 점화 장치를 켬으로써 해제 할 수 있습니다.
```

