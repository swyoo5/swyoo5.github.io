---
layout: single
title:  "[LLM] Chain-of-Retrieval Augmented Generation"
categories: [Programming, LLM, RAG, Project]
tag: [Programming, LLM, RAG, Project]
toc: true
author_profile: false
sidebar:
    nav: "docs"
---

[Chain-of-Retrieval Augmented Generation](https://arxiv.org/pdf/2501.14342)

# 배경

- 표준 RAG 시스템의 경우 질문을 입력했을 때, 한번만 검색을 수행하고, 관련 문서 목록을 가져온 다음, LLM이 검색된 문서를 사용하여 답변을 작성
- 이러한 방식의 경우 복잡한 질문, 여러 사실을 결합하거나 멀티홉 질문의 경우, 한 번의 검색만으로 충분한 정보를 검색할 수 없다는 한계가 있음
- 한번의 검색으로 필요한 정보를 찾지 못하거나, 추론의 단계에서 필요한 세부 정보를 놓칠 수 있음

# 해결책 : Chain-of-Retrieval(CoRAG)

- CoRAG는 이러한 문제를 해결하기 위해 검색을 다단계로 수행 
- 첫 검색 이후 후속 질문을 만들어내 단계별로 검색을 수행
- 프로세스 순서

1. 원본 질문으로 검색
2. i 단계 검색(i = 1, …, n)
3. 동적 하위 쿼리 생성 : 아래의 컨텍스트를 바탕으로 LLM이 특정 업무를 수행하는 데 필요한 정보가 무엇인지 결정
   1. 원본 질문(예 : 인터넷 발명가가 태어난 나라의 수도는 어디인가요?)
   2. 이전 단계에서 물었던 질문(누가 인터넷을 발명했나요? → 팀 버너스 리는 어디서 태어났나요? → [출생국]의 수도는 어디인가요?)
   3. 이전 단계의 검색 결과에서 얻은 모든 답변
4. 정보 수집
   1. LLM이 생성한 하위 쿼리 Q_i는 검색기로 전송
   2. Q_i와 관련된 문서 검색
   3. LLM이 검색된 문서를 읽고 하위 답변 A_i 생성
   4. 검색된 문서가 하위 쿼리에 도움이 되지 않는 경우 → 관련된 정보를 찾을 수 없음
5. 체인 구축
   1. 각 단계(하위 쿼리, 하위 답변, 문서) 쌍의 시퀀스가 검색 체인을 형성(단계별 정보 검색 및 수집)
6. 체인 중단
   1. 1~5 프로세스는 설정된 최대 Threshold까지 반복.
7. 최종 답변 제공
   1. 검색 체인이 완료되면 LLM은 프로세스의 전체 기록(원본 쿼리, 모든 하위 쿼리, 모든 하위 답변)을 가져와 이 정보들을 사용하여 복잡한 질문에 대한 최종 답변을 함께 생성