---
layout: single
title:  "[LLM] MCP(Model Context Protocol)"
categories: [Programming, LLM, RAG, Project]
tag: [Programming, LLM, RAG, Project]
toc: true
author_profile: false
sidebar:
    nav: "docs"
---

# 개요

LLM은 텍스트 생성에서 놀라운 성능을 보이지만, 텍스트나 특정 포맷의 데이터가 아닌 정보를 직접 접근하고, 이해하는 능력은 제한적이다.

이를 보완하기 위해 등장한 것이 MCP이다. MCP는 LLM과 외부 비정형 데이터 소스 간의 중계 및 전처리 역할을 수행함으로써 LLM이 이러한 데이터를 간접적으로 이해할 수 있게 해주는 프로토콜이다.

# LLM의 한계

대부분의 언어 모델은 텍스트 기반의 학습 구조를 가지고 있으며, 다음과 같은 데이터를 “직접” 처리할 수 없다.

- 영상/오디오 파일
- PDF, 워드 등 문서파일
- 실시간 데이터베이스 쿼리 결과

## 예시

**사용자 입력 : 이 유투브 영상 내용을 요약해줘 → “**[**https://youtube.com/watch?v=abcd”**](https://deep-ai-web.atlassian.net/wiki/spaces/MW/pages/126255135/MCP+Model+Context+Protocol#)

일반적인 LLM 모델은 링크에 직접 접근할 수 없고, 해당 요청을 무시할 가능성이 크다.

# MCP 개념

## 정의

MCP는 LLM이 직접 처리하지 못하는 외부 데이터를 텍스트 기반의 구조화된 입력으로 변환하여 전달하는 중간 계층의 역할을 한다.

## 시스템 구조

| **구성요소** | **설명**                                             |
| :----------- | :--------------------------------------------------- |
| MCP client   | LLM 내에 내장, 요청 판단 모듈                        |
| MCP Server   | 외부 데이터 소스에 직접 접근, 전처리를 수행하는 엔진 |

## 역할

- MCP client
  - LLM이 처리중인 요청 분석
  - 이 요청에 필요한 데이터 파악
  - 요청을 서버에 전달
- MCP Server
  - 해당 요청에 필요한 정보 수집
  - 외부 데이터에서 필요한 내용 추출
  - 정제된 정보를 JSON-RPC 2.0 메시지 포맷 형태로 반환
  - [JSON-RPC 2.0 메시지 포맷](https://wikidocs.net/268813)

# 동작 예시

## 유튜브 영상 요약

1. 사용자 요청 → LLM : “[www.youtube.com](http://www.youtube.com/) 이 영상 요약해줘”
2. MCP client : 요청을 분석하고, 영상 콘텐츠 필요하다고 판단
3. MCP Server 호출 : 영상 자막 추출 + 음성 → 텍스트화 + 문장 정제
4. 서버 응답 : 

```
{  "source_type": "video",  "source_link": "https://youtube.com/watch?v=abcd ",  "transcript": "이 영상은 자동차 미끄럼 방지에 대한 설명이며, 주요 내용은..." }
```

1. LLM 처리 : 정제된 형식의 내용을 인식하여 영상 요약 생성

## PDF 기반 Q&A

1. 사용자 요청 → LLM : “눈길에서 바퀴가 안미끄러지려면?”
2. MCP client : 문서 기반 정보가 필요함을 인식
3. MCP Server 호출 : 차량 메뉴얼 PDF에서 키워드 기반 문맥 추출
4. 서버 응답 : 

```
{  "source": "차량_매뉴얼_2024.pdf",  "matching_sections": [    "눈길 주행 시, 타이어 체인을 사용하세요.",    "ESP 기능을 활성화하십시오."  ] }
```

1. LLM 처리 : 추출된 문장을 바탕으로 근거 기반의 응답 생성

# 효과

- 다양한 비정형 데이터 형식을 구조화된 json 형태로 LLM에 전달
- RAG와 결합 시 문서/DB 정확한 출처 기반 응답 가능
- 클라이언트-서버 구조로 확장성 우수

 